
[{"content":"","date":"28 April 2024","externalUrl":null,"permalink":"/","section":"hwanzar","summary":"","title":"hwanzar","type":"page"},{"content":"Gonna start to note some linux stuff here.\n","date":"28 April 2024","externalUrl":null,"permalink":"/posts/linux-sandbox/","section":"Posts","summary":"Gonna start to note some linux stuff here.","title":"Linux notes","type":"posts"},{"content":"","date":"28 April 2024","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":" Convolutional Neural Network # Convolutional Neural Networks (CNNs) constitute a cornerstone in deep learning theory, specifically designed for processing grid-like data like images and video. The canonical architecture encompasses convolutional layers, where learnable filters convolve across input data, extracting hierarchical and spatial features. Subsequent pooling layers facilitate downsampling, enhancing translation invariance. These are often followed by fully connected layers and non-linear activation functions to model complex relationships. The complete suite of layers typically includes input layers, convolutional layers, pooling layers, fully connected layers, and output layers, collectively orchestrating the network\u0026rsquo;s ability to learn intricate patterns and representations for diverse tasks such as image recognition and object detection.\nThe inception of Convolutional Neural Networks (CNNs) marked a significant milestone in neural network architecture, with the Neocognitron standing as a pioneering precursor to this revolutionary development. The Neocognitron paper introduced groundbreaking concepts such as feature extraction, pooling layers, and the integration of convolution within a neural network for recognition or classification purposes. Inspired by the visual nervous system of vertebrates, the Neocognitron structured its network with alternating layers of S-cells (simple cells or lower-order hypercomplex cells) and C-cells (complex cells or higher-order hypercomplex cells). This arrangement facilitated the repeated process of feature extraction by S-cells and positional shift tolerance by C-cells(see Figure 1). The network\u0026rsquo;s overarching design, resembling the visual nervous system, enabled the gradual integration of local features into more global representations. Utilized for tasks like handwritten (Japanese) character recognition, the Neocognitron laid the foundation for subsequent Convolutional Neural Networks, influencing their application in diverse pattern recognition tasks.\nNeocognitron Network created by Japanese The idea of the convolution operation in a Convolutional layer might derive from the signal processing study. From two signals (or two functions), denoted by \\(f\\) and \\(g\\), we create the third function \\(f * g\\). This derived function intricately expresses the transformation of one function\u0026rsquo;s shape under the influence of the other, emphasizing the interplay and modification of their respective mathematical structures.\nSignal pulses of function f and g and the result of the convolutional operation Two-dimensional convolutional layer # As mentioned above, convolution is a mathematical operation involving two functions with a real-valued variable. In essence, the operation \\(*\\) is essentially the integration of the product of two functions. However, in some computational-related fields, the formula can be represented as discrete function, as others called discrete convolution: $$s(t) = (x * w)(t) = \\sum_{a= -\\infty}^{\\infty} x(a)w(t-a)$$\nIn this term, the variable x represents the input, while the variable w represents the kernel or filter. The output s is often called the output.\n","date":"14 January 2024","externalUrl":null,"permalink":"/posts/first-blog/","section":"Posts","summary":"Convolutional Neural Network # Convolutional Neural Networks (CNNs) constitute a cornerstone in deep learning theory, specifically designed for processing grid-like data like images and video.","title":"A little knowledge about CNN","type":"posts"},{"content":" About Me Hi there! I\u0026rsquo;m Dang Hoang Gia, but most people call me Zar.\nBackground I\u0026rsquo;m currently a student at Ho Chi Minh City University of Technology, where I\u0026rsquo;m pursuing my passion for Computer Engineering. Ever since I was young, I\u0026rsquo;ve been fascinated by technology and computers. This curiosity led me to choose Computer Engineering as my major, and I haven\u0026rsquo;t looked back since.\nInterests I have a keen interest in delving deep into the inner workings of computers. Specifically, I\u0026rsquo;m intrigued by computer performance optimization, understanding how computer architectures function, and exploring various aspects of system-on-chip (SoC) design.\nGoals My ultimate goal is to gain a comprehensive understanding of computer systems and their components. I aspire to contribute to the advancement of technology by leveraging my knowledge and skills in Computer Engineering.\nHobbies When I\u0026rsquo;m not buried in textbooks or coding away on my computer, you can find me exploring new technologies, tinkering with hardware, or enjoying outdoor activities like hiking and cycling.\nGet in Touch I\u0026rsquo;m always eager to connect with like-minded individuals who share my passion for technology. Feel free to reach out to me if you\u0026rsquo;d like to discuss anything related to computer engineering, exchange ideas, or simply chat about the latest tech trends.\nLet\u0026rsquo;s embark on this exciting journey together!\n","date":"1 January 0001","externalUrl":null,"permalink":"/about-me/","section":"hwanzar","summary":"About Me Hi there!","title":"About me","type":"page"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]